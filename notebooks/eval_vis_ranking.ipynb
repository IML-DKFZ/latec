{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path(os.getcwd()).parents[0])\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import sem\n",
    "\n",
    "from src.utils.plot_utils import *\n",
    "\n",
    "\n",
    "def NormalizeData(data, min, max):\n",
    "    return (data - min) / ((max - min) + 0.00000000001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Evaluation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File loading per dataset\n",
    "\n",
    "file_image_inet = \"/image/eval_scores_imagenet.npz\"\n",
    "file_image_oct = \"/image/eval_scores_oct.npz\"\n",
    "file_image_r45 = \"/image/eval_scores_resisc45.npz\"\n",
    "\n",
    "file_volume_adr = \"/volume/eval_scores_adrenalmnist3d.npz\"\n",
    "file_volume_org = \"/volume/eval_scores_organmnist3d.npz\"\n",
    "file_volume_ves = \"/volume/eval_scores_vesselmnist3d.npz\"\n",
    "\n",
    "file_pc_coma = \"/point_cloud/eval_scores_coma.npz\"\n",
    "file_pc_m40 = \"/point_cloud/eval_scores_modelnet40.npz\"\n",
    "file_pc_shpn = \"/point_cloud/eval_scores_shapenet.npz\"\n",
    "\n",
    "file_loc = os.getcwd() + \"/data/evaluation_scores\"\n",
    "\n",
    "file = np.load(file_loc + file_image_inet, allow_pickle=True)\n",
    "arr_image_inet = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_image_oct, allow_pickle=True)\n",
    "arr_image_oct = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_image_r45, allow_pickle=True)\n",
    "arr_image_r45 = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "\n",
    "file = np.load(file_loc + file_volume_adr, allow_pickle=True)\n",
    "arr_volume_adr = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_volume_org, allow_pickle=True)\n",
    "arr_volume_org = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_volume_ves, allow_pickle=True)\n",
    "arr_volume_ves = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "\n",
    "file = np.load(file_loc + file_pc_coma, allow_pickle=True)\n",
    "arr_pc_coma = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_pc_m40, allow_pickle=True)\n",
    "arr_pc_m40 = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_pc_shpn, allow_pickle=True)\n",
    "arr_pc_shpn = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_image = [arr_image_inet, arr_image_oct, arr_image_r45]\n",
    "arr_volume = [arr_volume_adr, arr_volume_org, arr_volume_ves]\n",
    "arr_pc = [arr_pc_coma, arr_pc_m40, arr_pc_shpn]\n",
    "arr_modalities = [arr_image, arr_volume, arr_pc]\n",
    "\n",
    "arr_ranking = np.empty(\n",
    "    [3, 3, 3, 17, 20], dtype=float\n",
    ")  # modality, dataset, model, xai, eval\n",
    "arr_ranking[:] = np.nan\n",
    "\n",
    "bup_order = [0, 1, 2, 4, 5, 7, 9, 12, 17]\n",
    "\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for model in range(3):\n",
    "            for xai in range(arr_modalities[modality][dataset][model].shape[0]):\n",
    "                for eval in range(20):\n",
    "                    ranking = np.median(\n",
    "                        arr_modalities[modality][dataset][model][:, eval, :], -1\n",
    "                    ).argsort()  # compute ranking based on median obs score\n",
    "                    if eval in bup_order:\n",
    "                        ranking = ranking[\n",
    "                            ::-1\n",
    "                        ]  # reverse ranking to bottom up if larger is better\n",
    "\n",
    "                    pos = (\n",
    "                        ranking.argsort()[xai] + 1\n",
    "                    )  # get rankin position of xai method (+1 so ranking starts at 1 and not 0)\n",
    "                    arr_ranking[modality, dataset, model, xai, eval] = pos\n",
    "\n",
    "arr_table = []\n",
    "for eval in range(20):\n",
    "    for modality in range(3):\n",
    "        for dataset in range(3):\n",
    "            arr_col_val = []\n",
    "            for model in [2]:\n",
    "                for xai in range(17):\n",
    "                    if modality == 2 and xai == 6:\n",
    "                        arr_col_val = arr_col_val + [\n",
    "                            np.round(np.mean(arr_ranking[(0, 1), :, :, 6, eval])),\n",
    "                            np.round(np.mean(arr_ranking[(0, 1), :, :, 7, eval])),\n",
    "                            np.round(np.mean(arr_ranking[(0, 1), :, :, 8, eval])),\n",
    "                        ]\n",
    "                    if modality == 2 and xai == 11:\n",
    "                        break\n",
    "                    x = arr_ranking[modality, dataset, model, xai, eval]\n",
    "                    val = np.round(np.mean(x[~np.isnan(x)]))\n",
    "                    arr_col_val.append(val)\n",
    "                arr_table.append(arr_col_val)\n",
    "\n",
    "df_table = pd.DataFrame(arr_table).transpose()\n",
    "df_table.index = [\n",
    "    \"OC\",\n",
    "    \"LIME\",\n",
    "    \"KS\",\n",
    "    \"VG\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "    \"RA\",\n",
    "    \"RoA\",\n",
    "    \"LA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking across Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_image = [arr_image_inet, arr_image_oct, arr_image_r45]\n",
    "arr_volume = [arr_volume_adr, arr_volume_org, arr_volume_ves]\n",
    "arr_pc = [arr_pc_coma, arr_pc_m40, arr_pc_shpn]\n",
    "arr_modalities = [arr_image, arr_volume, arr_pc]\n",
    "\n",
    "arr_ranking = np.empty([3, 17, 20], dtype=float)  # modality, dataset, xai, eval\n",
    "arr_ranking[:] = np.nan\n",
    "\n",
    "bup_order = [0, 1, 2, 4, 5, 7, 9, 12, 17]\n",
    "\n",
    "for modality in range(3):\n",
    "    for eval in range(20):\n",
    "        arr_scores = []\n",
    "        for model in range(3):\n",
    "            for data in range(3):\n",
    "                d = arr_modalities[modality][data][model][:, eval, :]\n",
    "                q_h = np.quantile(d, 0.975)\n",
    "                q_l = np.quantile(d, 0.025)\n",
    "\n",
    "                d = np.clip(d, q_l, q_h)\n",
    "                d_max = d.max()\n",
    "                d_min = d.min()\n",
    "                arr_scores.append(NormalizeData(d, d_min, d_max))\n",
    "\n",
    "        model_1 = np.column_stack(\n",
    "            (\n",
    "                np.median(arr_scores[0], 1),\n",
    "                np.median(arr_scores[1], 1),\n",
    "                np.median(arr_scores[2], 1),\n",
    "            )\n",
    "        )\n",
    "        model_2 = np.column_stack(\n",
    "            (\n",
    "                np.median(arr_scores[3], 1),\n",
    "                np.median(arr_scores[4], 1),\n",
    "                np.median(arr_scores[5], 1),\n",
    "            )\n",
    "        )\n",
    "        model_3 = np.column_stack(\n",
    "            (\n",
    "                np.median(arr_scores[6], 1),\n",
    "                np.median(arr_scores[7], 1),\n",
    "                np.median(arr_scores[8], 1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ranking = np.concatenate(\n",
    "            [\n",
    "                np.mean(\n",
    "                    np.hstack([model_1, model_2, model_3[:-3]]),\n",
    "                    -1,\n",
    "                ),\n",
    "                np.mean(model_3[-3:], -1),\n",
    "            ]\n",
    "        ).argsort()\n",
    "        # compute ranking based on median obs score\n",
    "        if eval in bup_order:\n",
    "            ranking = ranking[::-1]  # reverse ranking to bottom up if larger is better\n",
    "\n",
    "        for xai in range(ranking.shape[0]):\n",
    "            pos = (\n",
    "                ranking.argsort()[xai] + 1\n",
    "            )  # get rankin position of xai method (+1 so ranking starts at 1 and not 0)\n",
    "            arr_ranking[modality, xai, eval] = pos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables as in Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_faith = arr_ranking[0, :, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16]].T.round(1)\n",
    "img_faith_table = np.column_stack(\n",
    "    (img_faith.mean(1).round(1), img_faith.std(1).round(1), img_faith)\n",
    ")\n",
    "np.savetxt(\"./img_faith.csv\", img_faith_table, delimiter=\",\")\n",
    "\n",
    "vol_faith = arr_ranking[1, :, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16]].T.round(1)\n",
    "vol_faith_table = np.column_stack(\n",
    "    (vol_faith.mean(1).round(1), vol_faith.std(1).round(1), vol_faith)\n",
    ")\n",
    "np.savetxt(\"./vol_faith.csv\", vol_faith_table, delimiter=\",\")\n",
    "\n",
    "pc_faith = arr_ranking[2, :, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16]].T.round(1)\n",
    "pc_faith_table = np.column_stack(\n",
    "    (pc_faith.mean(1).round(1), pc_faith.std(1).round(1), pc_faith)\n",
    ")\n",
    "np.savetxt(\"./pc_faith.csv\", pc_faith_table, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rob = arr_ranking[0, :, [10, 11, 12, 13, 14, 15]].T.round(1)\n",
    "img_rob_table = np.column_stack(\n",
    "    (img_rob.mean(1).round(1), img_rob.std(1).round(1), img_rob)\n",
    ")\n",
    "np.savetxt(\"./img_rob.csv\", img_rob_table, delimiter=\",\")\n",
    "\n",
    "vol_rob = arr_ranking[1, :, [10, 11, 12, 13, 14, 15]].T.round(1)\n",
    "vol_rob_table = np.column_stack(\n",
    "    (vol_rob.mean(1).round(1), vol_rob.std(1).round(1), vol_rob)\n",
    ")\n",
    "np.savetxt(\"./vol_rob.csv\", vol_rob_table, delimiter=\",\")\n",
    "\n",
    "pc_rob = arr_ranking[2, :, [10, 11, 12, 13, 14, 15]].T.round(1)\n",
    "pc_rob_table = np.column_stack(\n",
    "    (pc_rob.mean(1).round(1), pc_rob.std(1).round(1), pc_rob)\n",
    ")\n",
    "np.savetxt(\"./pc_rob.csv\", pc_rob_table, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_comp = arr_ranking[0, :, [17, 18, 19]].T.round(1)\n",
    "img_comp_table = np.column_stack(\n",
    "    (img_comp.mean(1).round(1), img_comp.std(1).round(1), img_comp)\n",
    ")\n",
    "np.savetxt(\"./img_comp.csv\", img_comp_table, delimiter=\",\")\n",
    "\n",
    "vol_comp = arr_ranking[1, :, [17, 18, 19]].T.round(1)\n",
    "vol_comp_table = np.column_stack(\n",
    "    (vol_comp.mean(1).round(1), vol_comp.std(1).round(1), vol_comp)\n",
    ")\n",
    "np.savetxt(\"./vol_comp.csv\", vol_comp_table, delimiter=\",\")\n",
    "\n",
    "pc_comp = arr_ranking[2, :, [17, 18, 19]].T.round(1)\n",
    "pc_comp_table = np.column_stack(\n",
    "    (pc_comp.mean(1).round(1), pc_comp.std(1).round(1), pc_comp)\n",
    ")\n",
    "np.savetxt(\"./pc_comp.csv\", pc_comp_table, delimiter=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS Scaling Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_table = []\n",
    "for eval in [(0, 10), (10, 17), (17, 20)]:\n",
    "    for modality in range(3):\n",
    "        arr_col_val = []\n",
    "        arr_col_std = []\n",
    "        for xai in range(17):\n",
    "            if modality == 2 and xai == 6:\n",
    "                arr_col_val = arr_col_val + [np.nan, np.nan, np.nan]\n",
    "            if modality == 2 and xai == 14:\n",
    "                break\n",
    "            x = arr_ranking[modality, :, xai, eval[0] : eval[1]]\n",
    "            val = np.round(np.mean(x[~np.isnan(x)]))\n",
    "            if not np.isnan(val):\n",
    "                val = int(val)\n",
    "            else:\n",
    "                val = np.nan\n",
    "            arr_col_val.append(val)\n",
    "        arr_table.append(arr_col_val)\n",
    "\n",
    "df_table = pd.DataFrame(arr_table).transpose()\n",
    "df_table.index = [\n",
    "    \"OC\",\n",
    "    \"LI\",\n",
    "    \"KS\",\n",
    "    \"VG\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "    \"RA\",\n",
    "    \"RoA\",\n",
    "    \"LA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS, TSNE\n",
    "\n",
    "mds = MDS(n_components=2, random_state=4)\n",
    "# mds = TSNE(perplexity= 10)\n",
    "X_transformed = mds.fit_transform(df_table)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "X_transformed[4, 0] = X_transformed[4, 0] - 4\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_transformed[:-3, 0],\n",
    "        y=X_transformed[:-3, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=[\n",
    "            \"OC\",\n",
    "            \"LIME\",\n",
    "            \"KS\",\n",
    "            \"VG\",\n",
    "            \"IxG\",\n",
    "            \"GB\",\n",
    "            \"GC\",\n",
    "            \"SC\",\n",
    "            \"C+\",\n",
    "            \"IG\",\n",
    "            \"EG\",\n",
    "            \"DL\",\n",
    "            \"DLS\",\n",
    "            \"LRP\",\n",
    "        ],\n",
    "        textposition=\"top right\",\n",
    "        name=\"Attribution\",\n",
    "        marker=dict(color=colors[0], size=8),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_transformed[-3:, 0],\n",
    "        y=X_transformed[-3:, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=[\"RA\", \"RoA\", \"LA\"],\n",
    "        textposition=\"top right\",\n",
    "        name=\"Attention\",\n",
    "        marker=dict(color=colors[2], size=8),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=550,\n",
    "    xaxis=dict(\n",
    "        title=\"Dim 1\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Dim 2\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"XAI Methods\", font=dict(family=\"Helvetica\", size=16, color=\"#000000\")\n",
    "    ),\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/mds_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg. Rank per XAI Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "x = [\n",
    "    [\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attention\",\n",
    "        \"Attention\",\n",
    "        \"Attention\",\n",
    "    ],\n",
    "    [\n",
    "        \"OC\",\n",
    "        \"LI\",\n",
    "        \"KS\",\n",
    "        \"VG\",\n",
    "        \"IxG\",\n",
    "        \"GB\",\n",
    "        \"GC\",\n",
    "        \"SC\",\n",
    "        \"C+\",\n",
    "        \"IG\",\n",
    "        \"EG\",\n",
    "        \"DL\",\n",
    "        \"DLS\",\n",
    "        \"LRP\",\n",
    "        \"RA\",\n",
    "        \"RoA\",\n",
    "        \"LA\",\n",
    "    ],\n",
    "]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.mean(df_table.iloc[:, :90], axis=1), 1),\n",
    "        name=\"Faithfullness\",\n",
    "        marker_color=colors[0],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(df_table.iloc[:, :90], axis=1), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\", array=np.round(sem(df_table.iloc[:, :90], axis=1), 2)\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.mean(df_table.iloc[:, 90:153], axis=1), 1),\n",
    "        name=\"Robustness\",\n",
    "        marker_color=colors[4],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(df_table.iloc[:, 90:153], axis=1), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\", array=np.round(sem(df_table.iloc[:, 90:153], axis=1), 2)\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.mean(df_table.iloc[:, 153:180], axis=1), 1),\n",
    "        name=\"Complexity\",\n",
    "        marker_color=colors[5],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(df_table.iloc[:, 153:180], axis=1), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\", array=np.round(sem(df_table.iloc[:, 153:180], axis=1), 2)\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"Evaluation Criteria\",\n",
    "        font=dict(family=\"Helvetica\", size=16, color=\"#000000\"),\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=1500,\n",
    ")\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/aa_full_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correltation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "\n",
    "\n",
    "df_corr = np.corrcoef(df_table)\n",
    "mask = np.ones_like(df_corr, dtype=bool)\n",
    "mask[:] = np.nan\n",
    "mask = np.triu(mask).T\n",
    "\n",
    "\n",
    "heat = go.Heatmap(\n",
    "    z=df_corr * mask,\n",
    "    x=df_table.index,\n",
    "    y=df_table.index,\n",
    "    text=df_corr * mask,\n",
    "    zmin=-1,  # Sets the lower bound of the color domain\n",
    "    zmax=1,\n",
    "    xgap=1,  # Sets the horizontal gap (in pixels) between bricks\n",
    "    ygap=1,\n",
    "    colorscale=[\n",
    "        [0, \"#B5545C\"],\n",
    "        [0.1, \"#B5545C\"],\n",
    "        [0.5, \"rgb(245, 245, 245)\"],\n",
    "        [0.9, \"#76BB40\"],\n",
    "        [1, \"#76BB40\"],\n",
    "    ],\n",
    "    coloraxis_colorbar=dict(\n",
    "        thicknessmode=\"pixels\",\n",
    "        thickness=10,\n",
    "        lenmode=\"pixels\",\n",
    "        len=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    width=600,\n",
    "    height=600,\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False,\n",
    "    yaxis_autorange=\"reversed\",\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=16),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[heat], layout=layout)\n",
    "\n",
    "# fig.write_image(os.getcwd().split(\"src\")[0] + \"data/figures/corr_total.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Rank per Evaluation Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=[\"Faithfullness\", \"Robustness\", \"Complexity\"],\n",
    "        y=[\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, :90]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, 90:153]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, 153:180]), 1),\n",
    "        ],\n",
    "        name=\"Attribution\",\n",
    "        marker_color=colors[0],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=[\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, :90]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, 90:153]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, 153:180]), 1),\n",
    "        ],\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=[\n",
    "                sem(df_table.iloc[:-3, :90], axis=None),\n",
    "                sem(df_table.iloc[:-3, 90:153], axis=None),\n",
    "                sem(df_table.iloc[:-3, 153:180], axis=None),\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=[\"Faithfullness\", \"Robustness\", \"Complexity\"],\n",
    "        y=[\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, :90]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, 90:153]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, 153:180]), 1),\n",
    "        ],\n",
    "        name=\"Attention\",\n",
    "        marker_color=colors[2],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=[\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, :90]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, 90:153]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, 153:180]), 1),\n",
    "        ],\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=[\n",
    "                sem(df_table.iloc[15:, :90], axis=None),\n",
    "                sem(df_table.iloc[15:, 90:153], axis=None),\n",
    "                sem(df_table.iloc[15:, 153:180], axis=None),\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"Evaluation Criteria\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"XAI Methods\", font=dict(family=\"Helvetica\", size=16, color=\"#000000\")\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=700,\n",
    ")\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "t1 = stats.ttest_ind(\n",
    "    a=df_table.iloc[:-3, :90].to_numpy().flatten(),\n",
    "    b=df_table.iloc[-3:, :90].to_numpy().flatten(),\n",
    "    equal_var=False,\n",
    ")[1]\n",
    "t2 = stats.ttest_ind(\n",
    "    a=df_table.iloc[:-3, 90:153].to_numpy().flatten(),\n",
    "    b=df_table.iloc[-3:, 90:153].to_numpy().flatten(),\n",
    "    equal_var=False,\n",
    ")[1]\n",
    "t3 = stats.ttest_ind(\n",
    "    a=df_table.iloc[:-3, 153:180].to_numpy().flatten(),\n",
    "    b=df_table.iloc[-3:, 153:180].to_numpy().flatten(),\n",
    "    equal_var=False,\n",
    ")[1]\n",
    "\n",
    "for i in range(3):\n",
    "    fig = add_p_value_annotation(\n",
    "        fig,\n",
    "        array_columns=[[-0.25 + i, 0.25 + i]],\n",
    "        p_value=[[t1, t2, t3][i]],\n",
    "        _format=dict(interline=0.06, text_height=1.08, color=\"black\"),\n",
    "    )\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/aa_aggr_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modality Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_table = []\n",
    "for modality in range(3):\n",
    "    for eval in range(20):\n",
    "        for dataset in range(3):\n",
    "            arr_col_val = []\n",
    "            for xai in range(17):\n",
    "                if modality == 2 and xai == 6:\n",
    "                    arr_col_val = arr_col_val + [np.nan, np.nan, np.nan]\n",
    "                if modality == 2 and xai == 14:\n",
    "                    break\n",
    "                val = arr_ranking[modality, dataset, xai, eval]\n",
    "                arr_col_val.append(val)\n",
    "            arr_table.append(arr_col_val)\n",
    "\n",
    "df_table = pd.DataFrame(arr_table).transpose()\n",
    "df_table.index = [\n",
    "    \"OC\",\n",
    "    \"LI\",\n",
    "    \"KS\",\n",
    "    \"SA\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "    \"RA\",\n",
    "    \"RoA\",\n",
    "    \"LA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "x1 = [\"Faithfullness\"] * 4 + [\"Robustness\"] * 4 + [\"Complexity\"] * 4\n",
    "x2 = [\"LI\", \"GC\", \"EG\", \"LA\"] * 3\n",
    "x = [x1, x2]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], :30], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 30:51], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 51:60], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        name=\"Image\",\n",
    "        marker_color=colors[0],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], :30], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 30:51], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 51:60], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=np.concatenate(\n",
    "                (\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], :30], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 30:51], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 51:60], axis=1),\n",
    "                ),\n",
    "                axis=None,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 60:90], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 90:111], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 111:120], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        name=\"Volume\",\n",
    "        marker_color=colors[3],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 60:90], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 90:111], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 111:120], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=np.concatenate(\n",
    "                (\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 60:90], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 90:111], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 111:120], axis=1),\n",
    "                ),\n",
    "                axis=None,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 120:150], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 150:171], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 171:180], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        name=\"Point Cloud\",\n",
    "        marker_color=colors[5],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 120:150], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 150:171], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 171:180], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=np.concatenate(\n",
    "                (\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 120:150], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 150:171], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 171:180], axis=1),\n",
    "                ),\n",
    "                axis=None,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods per Evaluation Criteria\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"Modality\", font=dict(family=\"Helvetica\", size=16, color=\"#000000\")\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=1500,\n",
    ")\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/mod_aggr_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
